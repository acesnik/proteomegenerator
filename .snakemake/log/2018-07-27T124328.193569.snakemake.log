Building DAG of jobs...
Using shell: /bin/bash
Provided cluster nodes: 50
Job counts:
	count	jobs
	1	AlignFastqReadsByRG
	1	ApplyBQSR
	1	BaseRecalibrator
	1	MarkDuplicates
	1	MergeUnmappedAndAlignedBAMs
	1	SortAndFixRealignedBamTags
	1	all
	7

rule AlignFastqReadsByRG:
    input: /lila/data/kentsis/testfiles/K052M2_test/k052_unaligned_r1.fastq, /lila/data/kentsis/testfiles/K052M2_test/k052_unaligned_r2.fastq
    output: out/K052_tumor}.aligned.bam
    jobid: 6
    benchmark: out/benchmarks/K052_tumor}.align.txt
    wildcards: SAMPLE_NAME=K052_tumor}

Submitted job 6 with external jobid 'Job <4280985> is submitted to default queue <cpuqueue>.'.
Finished job 6.
1 of 7 steps (14%) done

rule MergeUnmappedAndAlignedBAMs:
    input: out/K052_tumor}.aligned.bam, out/K052_tumor}.unaligned.bam
    output: out/K052_tumor}.aligned_unaligned_merged.bam
    jobid: 5
    wildcards: SAMPLE_NAME=K052_tumor}

Submitted job 5 with external jobid 'Job <4280989> is submitted to default queue <cpuqueue>.'.
Finished job 5.
2 of 7 steps (29%) done

rule MarkDuplicates:
    input: out/K052_tumor}.aligned_unaligned_merged.bam
    output: out/K052_tumor.merged.RGmerged.dedup.bam
    jobid: 4
    wildcards: SAMPLE_NAME=K052_tumor

Submitted job 4 with external jobid 'Job <4280998> is submitted to default queue <cpuqueue>.'.
Terminating processes on user request, this might take some time.
Will exit after finishing currently running jobs.
Cancelling snakemake on user request.
